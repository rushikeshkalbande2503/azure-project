<h1>Project Statement:</h1>
Analyzing Olympic2023 Data for Event Optimization

<h1>Problem Description:</h1>
The primary objective of this project is to use the "Olympic2023" dataset to optimize the organization and management of the 2023 Olympic Games. 

<h1>Azure Servics used :</h1>

<li>Azure Storage Account</li>
<li>Azure Data Factory</li>
<li>Azure synapsis Analytics</li>
<li>Azure Databricks</li>

<h1>Tool Used:</h1>
<li>PowerBi</li>

<h1>Data Sources</h1>
The project will primarily utilize the "Olympic2023" dataset, which contains comprehensive information about the participating countries, athletes, sports, events, schedules, and results.

<h1>Steps followed While Deploying :</h1>
<b>1.Code and Pipeline Testing:</b><br>
Ensure that your data engineering code, ETL processes, and data pipelines are thoroughly tested in a development or test environment before deployment.

<b>2.Data Preparation:</b> <br>
Prepare the data for deployment, including data cleaning, transformation, and validation, as necessary.

<b>3.Azure Resource Provisioning:</b> <br>
Provision or configure the necessary Azure resources, including Azure Data Factory, Azure Databricks, Azure Synapse, and Azure Storage, to host your data engineering solutions.

<b>4.Database Setup:</b> <br>
Setting Up database in azure synapsis.

<b>5.Data Ingestion:</b> <br>
Ingest the data from  sources into the Azure storage or data warehouse, typically using data pipelines within Azure Data Factory.

<b>6.ETL Process Deployment:</b> <br>

<b>7.Created Dashboard Based on the data that we gathered in the transformed_data directory.</b> 

<h1>Implementation Video Link:</h1>
https://drive.google.com/file/d/1d3bgRLW-THM4Y7TSmcA7rBkMKBYcYavW/view?usp=sharing




















